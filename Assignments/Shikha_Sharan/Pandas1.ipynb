{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports go at the top, even though python is a very open language\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n",
      "\n",
      "a    1.0\n",
      "b    2.0\n",
      "c    3.0\n",
      "d    NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normal series and series with custom index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "s1 = pd.Series([1,2,3])\n",
    "s2 = pd.Series([1,2,3, np.nan], index=list(\"abcd\"))\n",
    "print(s1)\n",
    "print()\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    1\n",
      "20    2\n",
      "30    3\n",
      "dtype: int64\n",
      "a    abcd\n",
      "b     123\n",
      "c     try\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s_1=pd.Series([1,2,3],index=[10,20,30])\n",
    "print(s_1)\n",
    "s_2=pd.Series([\"abcd\",\"123\",\"try\"],index=('a','b','c'))\n",
    "print(s_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# changing dtype: astypepe\n",
    "print(type(s1))\n",
    "print(s1.dtype)\n",
    "print(type(s2))\n",
    "print(s2.dtype)\n",
    "print(type(s_1))\n",
    "print(s_1.dtype)\n",
    "print(type(s_2))\n",
    "print(s_2.dtype)\n",
    "r=s1.astype(\"float\")\n",
    "print(r.dtype)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "3\n",
      "RangeIndex(start=0, stop=3, step=1)\n"
     ]
    }
   ],
   "source": [
    "# shape, size, dtype, index, values\n",
    "print(s1.shape)\n",
    "print(s1.size)\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate operations: min, max, unique, sum etc.\n",
    "s1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(s1.min())\n",
    "print(s1.max())\n",
    "print(s1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, [10, 20]]\n",
      "\n",
      "[10, 20, 30, [10, 20, 40]]\n",
      "[10, 20, 30, [10, 20, 40]]\n",
      "[10, 20, 30, [10, 20]]\n",
      "[10, 20, 30, [10, 20]]\n",
      "[10, 20, 30, [10, 20]]\n",
      "[10, 20, 30, [10, 20, 40]]\n"
     ]
    }
   ],
   "source": [
    "# arithmetic operations(new copy) and broadcast like numpy\n",
    "import copy \n",
    "b=copy.copy(a)\n",
    "print(b)\n",
    "print()\n",
    "a[3].append(40)\n",
    "print(b)\n",
    "print(a)\n",
    "a1=[10,20,30,[10,20]]\n",
    "b1=copy.deepcopy(a1)\n",
    "print(a1)\n",
    "print(b1)\n",
    "a1[3].append(40)\n",
    "print(b1)\n",
    "print(a1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "dtype: int64\n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "a   NaN\n",
      "b   NaN\n",
      "c   NaN\n",
      "d   NaN\n",
      "dtype: float64\n",
      "a    1.0\n",
      "b    2.0\n",
      "c    3.0\n",
      "d    NaN\n",
      "dtype: float64\n",
      "0    2\n",
      "1    4\n",
      "2    5\n",
      "dtype: int64\n",
      "0     2\n",
      "1     8\n",
      "2    15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Arithmetic operations and broadcasting follows:\n",
    "r=s1*10\n",
    "print(r)\n",
    "print()\n",
    "print(s1)\n",
    "\n",
    "r1=s1+s2\n",
    "print(r1) #Operation done on the indexes.if indexes match then only operations otherwise not.\n",
    "print(s2)\n",
    "s3=pd.Series([2,4,5])\n",
    "print(s3)\n",
    "r2=s1*s3\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# indexing and slicing\n",
    "print(s1[0])\n",
    "print(s3[2])\n",
    "print(r2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of operations as index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.0\n",
      "b    2.0\n",
      "c    3.0\n",
      "d    NaN\n",
      "dtype: float64\n",
      "3.0    1\n",
      "2.0    1\n",
      "1.0    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequency : value_counts\n",
    "print(s2)\n",
    "r=s2.value_counts()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Age  Gender\n",
      "0     Gaurav  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     NaN\n",
      "8       na-2  NaN     0.0\n",
      "9        NaN  2.0     0.0\n",
      "\n",
      "         Name  Number\n",
      "0      Gaurav       1\n",
      "11   Abhiskek       2\n",
      "2     Krishna       3\n",
      "3   Abhishek2       4\n"
     ]
    }
   ],
   "source": [
    "# dataframe from dict or list of rows\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\":   [\"Gaurav\", \"Abhishek1\", \"Krishna\", \"Abhishek2\", \"Harshita\", \"Joey\", \"Shweta\", \"na-1\" , \"na-2\"  , np.nan],\n",
    "        \"Age\":    [ 0      , 1          , 2        , 2          , 1         , 2     , 3       , 1      ,  np.nan , 2     ],\n",
    "        \"Gender\": [ 0      , 0          , 0        , 0          , 1         , 1     , 1       , np.nan ,  0      , 0     ]\n",
    "    }\n",
    ")\n",
    "df2 = pd.DataFrame([(\"Gaurav\",1), (\"Abhiskek\",2), (\"Krishna\",3), (\"Abhishek2\",4)],\n",
    "                    index=[0,11,2,3], \n",
    "                    columns=[\"Name\", \"Number\"])\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "30\n",
      "object\n",
      "object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex(start=0, stop=10, step=1)\n",
      "Index(['Name', 'Age', 'Gender'], dtype='object')\n",
      "float64\n",
      "Name      9\n",
      "Age       9\n",
      "Gender    9\n",
      "dtype: int64\n",
      "2.0    4\n",
      "1.0    3\n",
      "3.0    1\n",
      "0.0    1\n",
      "Name: Age, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape, size, dtype, index, columns, unique, T\n",
    "print(df1.shape)\n",
    "print(df1.size)\n",
    "print(df1.values.dtype)\n",
    "print(df2.values.dtype)\n",
    "print(type(df1))\n",
    "print(df1.index)\n",
    "print(df1.columns)\n",
    "print(df1.Age.dtype)\n",
    "print(df1.count())\n",
    "print(df1.Age.value_counts())\n",
    "df1.Age.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         naam  num\n",
      "0      Gaurav    1\n",
      "11   Abhiskek    2\n",
      "2     Krishna    3\n",
      "3   Abhishek2    4\n",
      "\n",
      "         naam  num\n",
      "0      Gaurav    1\n",
      "11   Abhiskek    2\n",
      "2     Krishna    3\n",
      "3   Abhishek2    4\n",
      "         NAAM  NUM\n",
      "0      Gaurav    1\n",
      "11   Abhiskek    2\n",
      "2     Krishna    3\n",
      "3   Abhishek2    4\n"
     ]
    }
   ],
   "source": [
    "# Rename index and columns on df2.\n",
    "# Inplace vs normal operation\n",
    "r=df2.rename({\"Name\":\"name\",\"Number\":\"num\"},axis = 1)\n",
    "print(r)\n",
    "print()\n",
    "df2.rename({\"Name\":\"naam\",\"Number\":\"num\"},axis=1,inplace= True)\n",
    "print(df2)\n",
    "df2.rename(lambda s:s.upper(),axis = \"columns\",inplace = True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Gaurav\n",
      "1    Abhishek1\n",
      "2      Krishna\n",
      "3    Abhishek2\n",
      "4     Harshita\n",
      "5         Joey\n",
      "6       Shweta\n",
      "7         na-1\n",
      "8         na-2\n",
      "9          NaN\n",
      "Name: Name, dtype: object\n",
      "0       Gaurav\n",
      "1    Abhishek1\n",
      "2      Krishna\n",
      "3    Abhishek2\n",
      "4     Harshita\n",
      "5         Joey\n",
      "6       Shweta\n",
      "7         na-1\n",
      "8         na-2\n",
      "9          NaN\n",
      "Name: Name, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       Gaurav\n",
       "1    Abhishek1\n",
       "2      Krishna\n",
       "3    Abhishek2\n",
       "4     Harshita\n",
       "5         Joey\n",
       "6       Shweta\n",
       "7         na-1\n",
       "8         na-2\n",
       "9          NaN\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing columns directly and via index. \n",
    "print(df1.Name)\n",
    "print(df1[\"Name\"])\n",
    "df1[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0       Shikha\n",
      "1    Abhishek1\n",
      "2      Krishna\n",
      "3    Abhishek2\n",
      "4     Harshita\n",
      "5         Joey\n",
      "6       Shweta\n",
      "7         na-1\n",
      "8         na-2\n",
      "9          NaN\n",
      "Name: Name, dtype: object\n",
      "<class 'list'>\n",
      "[0       Shikha\n",
      "1    Abhishek1\n",
      "2      Krishna\n",
      "3    Abhishek2\n",
      "4     Harshita\n",
      "5         Joey\n",
      "6       Shweta\n",
      "7         na-1\n",
      "8         na-2\n",
      "9          NaN\n",
      "Name: Name, dtype: object]\n",
      "<class 'list'>\n",
      "[0       Shikha\n",
      "1    Abhishek1\n",
      "2      Krishna\n",
      "3    Abhishek2\n",
      "4     Harshita\n",
      "5         Joey\n",
      "6       Shweta\n",
      "7         na-1\n",
      "8         na-2\n",
      "9          NaN\n",
      "Name: Name, dtype: object]\n",
      "\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     NaN\n",
      "8       na-2  NaN     0.0\n",
      "9        NaN  2.0     0.0\n",
      "[1, 2, 3, 4] <class 'list'>\n",
      "10\n",
      "0     1\n",
      "11    2\n",
      "2     3\n",
      "3     4\n",
      "Name: NUM, dtype: int64\n",
      "[10, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-de3a8ff35908>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[0][0]=\"Shikha\"\n"
     ]
    }
   ],
   "source": [
    "# Series in a DataFrame\n",
    "print(type(df1.Name))\n",
    "print(df1.Name)\n",
    "a=[]\n",
    "print(type(a))\n",
    "a.append(df1.Name)\n",
    "print(a)\n",
    "print(type(a))\n",
    "a[0][0]=\"Shikha\"\n",
    "print(a)\n",
    "print()\n",
    "print(df1)\n",
    "b=list(df2.NUM)\n",
    "print(b,type(b))\n",
    "b[0]=10\n",
    "print(b[0])\n",
    "print(df2.NUM)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name       Age    Gender\n",
      "count      9  9.000000  9.000000\n",
      "unique     9       NaN       NaN\n",
      "top     na-2       NaN       NaN\n",
      "freq       1       NaN       NaN\n",
      "mean     NaN  1.555556  0.333333\n",
      "std      NaN  0.881917  0.500000\n",
      "min      NaN  0.000000  0.000000\n",
      "25%      NaN  1.000000  0.000000\n",
      "50%      NaN  2.000000  0.000000\n",
      "75%      NaN  2.000000  1.000000\n",
      "max      NaN  3.000000  1.000000\n",
      "\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "\n",
      "     Name  Age  Gender\n",
      "5    Joey  2.0     1.0\n",
      "6  Shweta  3.0     1.0\n",
      "7    na-1  1.0     NaN\n",
      "8    na-2  NaN     0.0\n",
      "9     NaN  2.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# describe, top/bottom rows of data\n",
    "print(df1.describe(include=\"all\"))\n",
    "print()\n",
    "print(df1.head())\n",
    "print()\n",
    "print(df1.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shikha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhishek1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Krishna</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhishek2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harshita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joey</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shweta</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>na-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>na-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Age  Gender\n",
       "0     Shikha  0.0     0.0\n",
       "1  Abhishek1  1.0     0.0\n",
       "2    Krishna  2.0     0.0\n",
       "3  Abhishek2  2.0     0.0\n",
       "4   Harshita  1.0     1.0\n",
       "5       Joey  2.0     1.0\n",
       "6     Shweta  3.0     1.0\n",
       "7       na-1  1.0     NaN\n",
       "8       na-2  NaN     0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing and slicing\n",
    "# loc, iloc [rows, cols]\n",
    "df1[\"Name\"]\n",
    "df1.iloc[1]\n",
    "df1.iloc[0:len(df1),0:3]\n",
    "df1.iloc[0:df1.shape[0]-1,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    1.0\n",
      "7    1.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "dtype: float64\n",
      "\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# aggregate operations (with and without axis : row-1, col-0)\n",
    "# min, max, count, ...\n",
    "print(df1.min(axis=1))\n",
    "print()\n",
    "print(df1.Age.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10.0\n",
      "1    11.0\n",
      "2    12.0\n",
      "3    12.0\n",
      "4    11.0\n",
      "5    12.0\n",
      "6    13.0\n",
      "7    11.0\n",
      "8     NaN\n",
      "9    12.0\n",
      "Name: Age, dtype: float64\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    1.0\n",
      "5    2.0\n",
      "6    3.0\n",
      "7    1.0\n",
      "8    NaN\n",
      "9    2.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# arithmetic operations\n",
    "print(df1.Age+10)\n",
    "print(df1.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name      1\n",
      "Age       1\n",
      "Gender    1\n",
      "dtype: int64\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     1.0\n",
      "8       na-2  1.0     0.0\n",
      "9        abc  2.0     0.0\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     NaN\n",
      "8       na-2  NaN     0.0\n",
      "9        NaN  2.0     0.0\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     1.0\n",
      "8       na-2  1.0     0.0\n",
      "9       na-2  2.0     0.0\n",
      "        Name  Age  Gender\n",
      "0     Shikha  0.0     0.0\n",
      "1  Abhishek1  1.0     0.0\n",
      "2    Krishna  2.0     0.0\n",
      "3  Abhishek2  2.0     0.0\n",
      "4   Harshita  1.0     1.0\n",
      "5       Joey  2.0     1.0\n",
      "6     Shweta  3.0     1.0\n",
      "7       na-1  1.0     0.0\n",
      "8       na-2  2.0     0.0\n",
      "9        NaN  2.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Na Values: isna, fillna, dropna\n",
    "print(df1.isna().sum())\n",
    "r=df1.fillna({\"Name\":\"abc\",\"Age\":1,\"Gender\":1})\n",
    "print(r)\n",
    "print(df1)\n",
    "r1=df1.fillna(method=\"ffill\")\n",
    "print(r1)\n",
    "r2=df1.fillna(method=\"bfill\")\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any, all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Abhishek1\n",
       "3    Abhishek2\n",
       "4     Harshita\n",
       "5         Joey\n",
       "2      Krishna\n",
       "0       Shikha\n",
       "6       Shweta\n",
       "7         na-1\n",
       "8         na-2\n",
       "9          NaN\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordering data, sort_values\n",
    "df1.Name.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0  15  19  15  10\n",
      "1  16  18  14  16\n",
      "2  15  12  19  18\n",
      "3  13  10  18  16\n",
      "4  12  17  18  10\n",
      "     0    1    2    3\n",
      "0  7.5  9.5  7.5  5.0\n",
      "1  8.0  9.0  7.0  8.0\n",
      "2  7.5  6.0  9.5  9.0\n",
      "3  6.5  5.0  9.0  8.0\n",
      "4  6.0  8.5  9.0  5.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'sort_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ff434734c2a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtmp1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtmp2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapplymap\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   6942\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6944\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6946\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[0;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36minfer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   6940\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6941\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-ff434734c2a7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtmp1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtmp2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'sort_index'"
     ]
    }
   ],
   "source": [
    "# row / column wise operation: apply\n",
    "tmp = pd.DataFrame(np.random.randint(10,20,20).reshape(5,4))\n",
    "print(tmp)\n",
    "tmp1= tmp.apply(lambda x:x/2)\n",
    "print(tmp1)\n",
    "tmp2=tmp.applymap(lambda x:x.sort_index())\n",
    "print(tmp2)\n",
    "\n",
    "#applymap() method only works on a pandas dataframe where function is applied on every element individually.\n",
    "\n",
    "#apply() method can be applied both to series and dataframes where function can be applied both series and individual elements based on the type of function provided.\n",
    "\n",
    "#map() method only works on a pandas series where type of operation to be applied depends on argument passed as a function, dictionary or a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str submodule (replace etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups: groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups and aggregates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-20 00:00:00 <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "['__add__', '__array_priority__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pyx_vtable__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rsub__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__weakref__', '_date_attributes', '_date_repr', '_get_date_name_field', '_get_start_end_field', '_has_time_component', '_repr_base', '_round', '_short_repr', '_time_repr', 'asm8', 'astimezone', 'ceil', 'combine', 'ctime', 'date', 'day', 'day_name', 'dayofweek', 'dayofyear', 'days_in_month', 'daysinmonth', 'dst', 'floor', 'fold', 'freq', 'freqstr', 'fromisocalendar', 'fromisoformat', 'fromordinal', 'fromtimestamp', 'hour', 'is_leap_year', 'is_month_end', 'is_month_start', 'is_quarter_end', 'is_quarter_start', 'is_year_end', 'is_year_start', 'isocalendar', 'isoformat', 'isoweekday', 'max', 'microsecond', 'min', 'minute', 'month', 'month_name', 'nanosecond', 'normalize', 'now', 'quarter', 'replace', 'resolution', 'round', 'second', 'strftime', 'strptime', 'time', 'timestamp', 'timetuple', 'timetz', 'to_datetime64', 'to_julian_date', 'to_numpy', 'to_period', 'to_pydatetime', 'today', 'toordinal', 'tz', 'tz_convert', 'tz_localize', 'tzinfo', 'tzname', 'utcfromtimestamp', 'utcnow', 'utcoffset', 'utctimetuple', 'value', 'week', 'weekday', 'weekofyear', 'year']\n",
      "Friday\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Timestamp' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9a4044112e28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Timestamp' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "#date_time\n",
    "r = pd.to_datetime(\"20-11-2020\",format=\"%d-%m-%Y\")\n",
    "print(r, type(r))\n",
    "print(dir(r))\n",
    "print(r.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2020-10-22\n",
      "1   2020-10-21\n",
      "2   2020-10-20\n",
      "dtype: datetime64[ns]\n",
      "['T', '_AXIS_ALIASES', '_AXIS_IALIASES', '_AXIS_LEN', '_AXIS_NAMES', '_AXIS_NUMBERS', '_AXIS_ORDERS', '_AXIS_REVERSED', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_add_numeric_operations', '_add_series_or_dataframe_operations', '_agg_by_level', '_agg_examples_doc', '_agg_see_also_doc', '_aggregate', '_aggregate_multiple_funcs', '_align_frame', '_align_series', '_binop', '_box_item_values', '_builtin_table', '_can_hold_na', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_dict_from', '_construct_axes_from_arguments', '_constructor', '_constructor_expanddim', '_constructor_sliced', '_convert', '_convert_dtypes', '_create_indexer', '_cython_table', '_deprecations', '_dir_additions', '_dir_deletions', '_drop_axis', '_drop_labels_or_levels', '_find_valid_index', '_from_axes', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_cleaned_column_resolvers', '_get_cython_func', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_get_values', '_get_values_tuple', '_get_with', '_gotitem', '_iget_item_cache', '_index', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_init_dict', '_init_mgr', '_internal_get_values', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cached', '_is_copy', '_is_datelike_mixed_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_numeric_mixed_type', '_is_view', '_ix', '_ixs', '_map_values', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_ndarray_values', '_needs_reindex_multi', '_obj_with_exclusions', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_indexer', '_reindex_multi', '_reindex_with_indexers', '_repr_data_resource_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_is_copy', '_set_item', '_set_labels', '_set_name', '_set_subtyp', '_set_value', '_set_values', '_set_with', '_set_with_engine', '_setup_axes', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_take_with_is_copy', '_to_dict_of_blocks', '_try_aggregate_string_function', '_typ', '_unpickle_series_compat', '_update_inplace', '_validate_dtype', '_values', '_where', '_xs', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'argmax', 'argmin', 'argsort', 'array', 'asfreq', 'asof', 'astype', 'at', 'at_time', 'attrs', 'autocorr', 'axes', 'between', 'between_time', 'bfill', 'bool', 'clip', 'combine', 'combine_first', 'convert_dtypes', 'copy', 'corr', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'divmod', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dt', 'dtype', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'ewm', 'expanding', 'explode', 'factorize', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'floordiv', 'ge', 'get', 'groupby', 'gt', 'hasnans', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'interpolate', 'is_monotonic', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'is_unique', 'isin', 'isna', 'isnull', 'item', 'items', 'iteritems', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lt', 'mad', 'map', 'mask', 'max', 'mean', 'median', 'memory_usage', 'min', 'mod', 'mode', 'mul', 'multiply', 'name', 'nbytes', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pct_change', 'pipe', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'radd', 'rank', 'ravel', 'rdiv', 'rdivmod', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'repeat', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'searchsorted', 'sem', 'set_axis', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'std', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_frame', 'to_hdf', 'to_json', 'to_latex', 'to_list', 'to_markdown', 'to_numpy', 'to_period', 'to_pickle', 'to_sql', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unique', 'unstack', 'update', 'value_counts', 'values', 'var', 'view', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "#datetime series\n",
    "dt_Series =pd.to_datetime(pd.Series([\"2020-10-22\",\"2020-10-21\",\"2020-10-20\"]),format=\"%Y-%m-%d\")\n",
    "print(dt_Series)\n",
    "print(dir(dt_Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DatetimeProperties in module pandas.core.indexes.accessors object:\n",
      "\n",
      "class DatetimeProperties(Properties)\n",
      " |  DatetimeProperties(data, orig)\n",
      " |  \n",
      " |  Accessor object for datetimelike properties of the Series values.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> s.dt.hour\n",
      " |  >>> s.dt.second\n",
      " |  >>> s.dt.quarter\n",
      " |  \n",
      " |  Returns a Series indexed like the original Series.\n",
      " |  Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DatetimeProperties\n",
      " |      Properties\n",
      " |      pandas.core.accessor.PandasDelegate\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.NoNewAttributesMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  ceil(self, *args, **kwargs)\n",
      " |      Perform ceil operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to ceil the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.ceil('H')\n",
      " |      DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 13:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.ceil(\"H\")\n",
      " |      0   2018-01-01 12:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 13:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  day_name(self, *args, **kwargs)\n",
      " |      Return the day names of the DateTimeIndex with specified locale.\n",
      " |      \n",
      " |      .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      locale : str, optional\n",
      " |          Locale determining the language in which to return the day name.\n",
      " |          Default is English locale.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of day names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      >>> idx.day_name()\n",
      " |      Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')\n",
      " |  \n",
      " |  floor(self, *args, **kwargs)\n",
      " |      Perform floor operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to floor the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.floor('H')\n",
      " |      DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.floor(\"H\")\n",
      " |      0   2018-01-01 11:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 12:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  month_name(self, *args, **kwargs)\n",
      " |      Return the month names of the DateTimeIndex with specified locale.\n",
      " |      \n",
      " |      .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      locale : str, optional\n",
      " |          Locale determining the language in which to return the month name.\n",
      " |          Default is English locale.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of month names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2018-01', freq='M', periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31'],\n",
      " |                    dtype='datetime64[ns]', freq='M')\n",
      " |      >>> idx.month_name()\n",
      " |      Index(['January', 'February', 'March'], dtype='object')\n",
      " |  \n",
      " |  normalize(self, *args, **kwargs)\n",
      " |      Convert times to midnight.\n",
      " |      \n",
      " |      The time component of the date-time is converted to midnight i.e.\n",
      " |      00:00:00. This is useful in cases, when the time does not matter.\n",
      " |      Length is unaltered. The timezones are unaffected.\n",
      " |      \n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on Datetime Array/Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeArray, DatetimeIndex or Series\n",
      " |          The same type as the original data. Series will have the same\n",
      " |          name and index. DatetimeIndex will have the same name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      floor : Floor the datetimes to the specified freq.\n",
      " |      ceil : Ceil the datetimes to the specified freq.\n",
      " |      round : Round the datetimes to the specified freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range(start='2014-08-01 10:00', freq='H',\n",
      " |      ...                     periods=3, tz='Asia/Calcutta')\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2014-08-01 10:00:00+05:30',\n",
      " |                     '2014-08-01 11:00:00+05:30',\n",
      " |                     '2014-08-01 12:00:00+05:30'],\n",
      " |                      dtype='datetime64[ns, Asia/Calcutta]', freq='H')\n",
      " |      >>> idx.normalize()\n",
      " |      DatetimeIndex(['2014-08-01 00:00:00+05:30',\n",
      " |                     '2014-08-01 00:00:00+05:30',\n",
      " |                     '2014-08-01 00:00:00+05:30'],\n",
      " |                     dtype='datetime64[ns, Asia/Calcutta]', freq=None)\n",
      " |  \n",
      " |  round(self, *args, **kwargs)\n",
      " |      Perform round operation on the data to the specified `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset\n",
      " |          The frequency level to round the index to. Must be a fixed\n",
      " |          frequency like 'S' (second) not 'ME' (month end). See\n",
      " |          :ref:`frequency aliases <timeseries.offset_aliases>` for\n",
      " |          a list of possible `freq` values.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          Only relevant for DatetimeIndex:\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DatetimeIndex, TimedeltaIndex, or Series\n",
      " |          Index of the same type for a DatetimeIndex or TimedeltaIndex,\n",
      " |          or a Series with the same index for a Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError if the `freq` cannot be converted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **DatetimeIndex**\n",
      " |      \n",
      " |      >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n",
      " |      >>> rng\n",
      " |      DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:01:00'],\n",
      " |                    dtype='datetime64[ns]', freq='T')\n",
      " |      >>> rng.round('H')\n",
      " |      DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n",
      " |                     '2018-01-01 12:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series(rng).dt.round(\"H\")\n",
      " |      0   2018-01-01 12:00:00\n",
      " |      1   2018-01-01 12:00:00\n",
      " |      2   2018-01-01 12:00:00\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  strftime(self, *args, **kwargs)\n",
      " |      Convert to Index using specified date_format.\n",
      " |      \n",
      " |      Return an Index of formatted strings specified by date_format, which\n",
      " |      supports the same string format as the python standard library. Details\n",
      " |      of the string format can be found in `python string format\n",
      " |      doc <https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior>`__.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      date_format : str\n",
      " |          Date format string (e.g. \"%Y-%m-%d\").\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          NumPy ndarray of formatted strings.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert the given argument to datetime.\n",
      " |      DatetimeIndex.normalize : Return DatetimeIndex with times to midnight.\n",
      " |      DatetimeIndex.round : Round the DatetimeIndex to the specified freq.\n",
      " |      DatetimeIndex.floor : Floor the DatetimeIndex to the specified freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> rng = pd.date_range(pd.Timestamp(\"2018-03-10 09:00\"),\n",
      " |      ...                     periods=3, freq='s')\n",
      " |      >>> rng.strftime('%B %d, %Y, %r')\n",
      " |      Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',\n",
      " |             'March 10, 2018, 09:00:02 AM'],\n",
      " |            dtype='object')\n",
      " |  \n",
      " |  to_period(self, *args, **kwargs)\n",
      " |      Cast to PeriodArray/Index at a particular frequency.\n",
      " |      \n",
      " |      Converts DatetimeArray/Index to PeriodArray/Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str or Offset, optional\n",
      " |          One of pandas' :ref:`offset strings <timeseries.offset_aliases>`\n",
      " |          or an Offset object. Will be inferred by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      PeriodArray/Index\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When converting a DatetimeArray/Index with non-regular values,\n",
      " |          so that a frequency cannot be inferred.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      PeriodIndex: Immutable ndarray holding ordinal values.\n",
      " |      DatetimeIndex.to_pydatetime: Return DatetimeIndex as object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"y\": [1, 2, 3]},\n",
      " |      ...                   index=pd.to_datetime([\"2000-03-31 00:00:00\",\n",
      " |      ...                                         \"2000-05-31 00:00:00\",\n",
      " |      ...                                         \"2000-08-31 00:00:00\"]))\n",
      " |      >>> df.index.to_period(\"M\")\n",
      " |      PeriodIndex(['2000-03', '2000-05', '2000-08'],\n",
      " |                  dtype='period[M]', freq='M')\n",
      " |      \n",
      " |      Infer the daily frequency\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-01-01\", periods=2)\n",
      " |      >>> idx.to_period()\n",
      " |      PeriodIndex(['2017-01-01', '2017-01-02'],\n",
      " |                  dtype='period[D]', freq='D')\n",
      " |  \n",
      " |  to_pydatetime(self)\n",
      " |      Return the data as an array of native Python datetime objects.\n",
      " |      \n",
      " |      Timezone information is retained if present.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         Python's datetime uses microsecond resolution, which is lower than\n",
      " |         pandas (nanosecond). The values are truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Object dtype array containing native Python datetime objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      datetime.datetime : Standard library value for a datetime.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(pd.date_range('20180310', periods=2))\n",
      " |      >>> s\n",
      " |      0   2018-03-10\n",
      " |      1   2018-03-11\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> s.dt.to_pydatetime()\n",
      " |      array([datetime.datetime(2018, 3, 10, 0, 0),\n",
      " |             datetime.datetime(2018, 3, 11, 0, 0)], dtype=object)\n",
      " |      \n",
      " |      pandas' nanosecond precision is truncated to microseconds.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range('20180310', periods=2, freq='ns'))\n",
      " |      >>> s\n",
      " |      0   2018-03-10 00:00:00.000000000\n",
      " |      1   2018-03-10 00:00:00.000000001\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> s.dt.to_pydatetime()\n",
      " |      array([datetime.datetime(2018, 3, 10, 0, 0),\n",
      " |             datetime.datetime(2018, 3, 10, 0, 0)], dtype=object)\n",
      " |  \n",
      " |  tz_convert(self, *args, **kwargs)\n",
      " |      Convert tz-aware Datetime Array/Index from one time zone to another.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str, pytz.timezone, dateutil.tz.tzfile or None\n",
      " |          Time zone for time. Corresponding timestamps would be converted\n",
      " |          to this time zone of the Datetime Array/Index. A `tz` of None will\n",
      " |          convert to UTC and remove the timezone information.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Array or Index\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If Datetime Array/Index is tz-naive.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DatetimeIndex.tz : A timezone that has a variable offset from UTC.\n",
      " |      DatetimeIndex.tz_localize : Localize tz-naive DatetimeIndex to a\n",
      " |          given time zone, or remove timezone from a tz-aware DatetimeIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      With the `tz` parameter, we can change the DatetimeIndex\n",
      " |      to other time zones:\n",
      " |      \n",
      " |      >>> dti = pd.date_range(start='2014-08-01 09:00',\n",
      " |      ...                     freq='H', periods=3, tz='Europe/Berlin')\n",
      " |      \n",
      " |      >>> dti\n",
      " |      DatetimeIndex(['2014-08-01 09:00:00+02:00',\n",
      " |                     '2014-08-01 10:00:00+02:00',\n",
      " |                     '2014-08-01 11:00:00+02:00'],\n",
      " |                    dtype='datetime64[ns, Europe/Berlin]', freq='H')\n",
      " |      \n",
      " |      >>> dti.tz_convert('US/Central')\n",
      " |      DatetimeIndex(['2014-08-01 02:00:00-05:00',\n",
      " |                     '2014-08-01 03:00:00-05:00',\n",
      " |                     '2014-08-01 04:00:00-05:00'],\n",
      " |                    dtype='datetime64[ns, US/Central]', freq='H')\n",
      " |      \n",
      " |      With the ``tz=None``, we can remove the timezone (after converting\n",
      " |      to UTC if necessary):\n",
      " |      \n",
      " |      >>> dti = pd.date_range(start='2014-08-01 09:00', freq='H',\n",
      " |      ...                     periods=3, tz='Europe/Berlin')\n",
      " |      \n",
      " |      >>> dti\n",
      " |      DatetimeIndex(['2014-08-01 09:00:00+02:00',\n",
      " |                     '2014-08-01 10:00:00+02:00',\n",
      " |                     '2014-08-01 11:00:00+02:00'],\n",
      " |                      dtype='datetime64[ns, Europe/Berlin]', freq='H')\n",
      " |      \n",
      " |      >>> dti.tz_convert(None)\n",
      " |      DatetimeIndex(['2014-08-01 07:00:00',\n",
      " |                     '2014-08-01 08:00:00',\n",
      " |                     '2014-08-01 09:00:00'],\n",
      " |                      dtype='datetime64[ns]', freq='H')\n",
      " |  \n",
      " |  tz_localize(self, *args, **kwargs)\n",
      " |      Localize tz-naive Datetime Array/Index to tz-aware\n",
      " |      Datetime Array/Index.\n",
      " |      \n",
      " |      This method takes a time zone (tz) naive Datetime Array/Index object\n",
      " |      and makes this time zone aware. It does not move the time to another\n",
      " |      time zone.\n",
      " |      Time zone localization helps to switch from time zone aware to time\n",
      " |      zone unaware objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str, pytz.timezone, dateutil.tz.tzfile or None\n",
      " |          Time zone to convert timestamps to. Passing ``None`` will\n",
      " |          remove the time zone information preserving local time.\n",
      " |      ambiguous : 'infer', 'NaT', bool array, default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False signifies a\n",
      " |            non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      \n",
      " |      nonexistent : 'shift_forward', 'shift_backward, 'NaT', timedelta, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST.\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as self\n",
      " |          Array/Index converted to the specified time zone.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the Datetime Array/Index is tz-aware and tz is not None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DatetimeIndex.tz_convert : Convert tz-aware DatetimeIndex from\n",
      " |          one time zone to another.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)\n",
      " |      >>> tz_naive\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',\n",
      " |                     '2018-03-03 09:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      Localize DatetimeIndex in US/Eastern time zone:\n",
      " |      \n",
      " |      >>> tz_aware = tz_naive.tz_localize(tz='US/Eastern')\n",
      " |      >>> tz_aware\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00-05:00',\n",
      " |                     '2018-03-02 09:00:00-05:00',\n",
      " |                     '2018-03-03 09:00:00-05:00'],\n",
      " |                    dtype='datetime64[ns, US/Eastern]', freq='D')\n",
      " |      \n",
      " |      With the ``tz=None``, we can remove the time zone information\n",
      " |      while keeping the local time (not converted to UTC):\n",
      " |      \n",
      " |      >>> tz_aware.tz_localize(None)\n",
      " |      DatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',\n",
      " |                     '2018-03-03 09:00:00'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas can\n",
      " |      infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:30:00',\n",
      " |      ...                               '2018-10-28 02:00:00',\n",
      " |      ...                               '2018-10-28 02:30:00',\n",
      " |      ...                               '2018-10-28 02:00:00',\n",
      " |      ...                               '2018-10-28 02:30:00',\n",
      " |      ...                               '2018-10-28 03:00:00',\n",
      " |      ...                               '2018-10-28 03:30:00']))\n",
      " |      >>> s.dt.tz_localize('CET', ambiguous='infer')\n",
      " |      0   2018-10-28 01:30:00+02:00\n",
      " |      1   2018-10-28 02:00:00+02:00\n",
      " |      2   2018-10-28 02:30:00+02:00\n",
      " |      3   2018-10-28 02:00:00+01:00\n",
      " |      4   2018-10-28 02:30:00+01:00\n",
      " |      5   2018-10-28 03:00:00+01:00\n",
      " |      6   2018-10-28 03:30:00+01:00\n",
      " |      dtype: datetime64[ns, CET]\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2018-10-28 01:20:00',\n",
      " |      ...                               '2018-10-28 02:36:00',\n",
      " |      ...                               '2018-10-28 03:46:00']))\n",
      " |      >>> s.dt.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      0   2015-03-29 03:00:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, Europe/Warsaw]\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backwards with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backwards'`.\n",
      " |      \n",
      " |      >>> s = pd.to_datetime(pd.Series(['2015-03-29 02:30:00',\n",
      " |      ...                               '2015-03-29 03:30:00']))\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      0   2015-03-29 03:00:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      0   2015-03-29 01:59:59.999999999+01:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |      >>> s.dt.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      0   2015-03-29 03:30:00+02:00\n",
      " |      1   2015-03-29 03:30:00+02:00\n",
      " |      dtype: datetime64[ns, 'Europe/Warsaw']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  freq\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  date\n",
      " |      Returns numpy array of python datetime.date objects (namely, the date\n",
      " |      part of Timestamps without timezone information).\n",
      " |  \n",
      " |  day\n",
      " |      The month as January=1, December=12.\n",
      " |  \n",
      " |  dayofweek\n",
      " |      The day of the week with Monday=0, Sunday=6.\n",
      " |      \n",
      " |      Return the day of the week. It is assumed the week starts on\n",
      " |      Monday, which is denoted by 0 and ends on Sunday which is denoted\n",
      " |      by 6. This method is available on both Series with datetime\n",
      " |      values (using the `dt` accessor) or DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or Index\n",
      " |          Containing integers indicating the day number.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dt.dayofweek : Alias.\n",
      " |      Series.dt.weekday : Alias.\n",
      " |      Series.dt.day_name : Returns the name of the day of the week.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n",
      " |      >>> s.dt.dayofweek\n",
      " |      2016-12-31    5\n",
      " |      2017-01-01    6\n",
      " |      2017-01-02    0\n",
      " |      2017-01-03    1\n",
      " |      2017-01-04    2\n",
      " |      2017-01-05    3\n",
      " |      2017-01-06    4\n",
      " |      2017-01-07    5\n",
      " |      2017-01-08    6\n",
      " |      Freq: D, dtype: int64\n",
      " |  \n",
      " |  dayofyear\n",
      " |      The ordinal day of the year.\n",
      " |  \n",
      " |  days_in_month\n",
      " |      The number of days in the month.\n",
      " |  \n",
      " |  daysinmonth\n",
      " |      The number of days in the month.\n",
      " |  \n",
      " |  hour\n",
      " |      The hours of the datetime.\n",
      " |  \n",
      " |  is_leap_year\n",
      " |      Boolean indicator if the date belongs to a leap year.\n",
      " |      \n",
      " |      A leap year is a year, which has 366 days (instead of 365) including\n",
      " |      29th of February as an intercalary day.\n",
      " |      Leap years are years which are multiples of four with the exception\n",
      " |      of years divisible by 100 but not by 400.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or ndarray\n",
      " |           Booleans indicating if dates belong to a leap year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2012-01-01\", \"2015-01-01\", freq=\"Y\")\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],\n",
      " |                    dtype='datetime64[ns]', freq='A-DEC')\n",
      " |      >>> idx.is_leap_year\n",
      " |      array([ True, False, False], dtype=bool)\n",
      " |      \n",
      " |      >>> dates = pd.Series(idx)\n",
      " |      >>> dates_series\n",
      " |      0   2012-12-31\n",
      " |      1   2013-12-31\n",
      " |      2   2014-12-31\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> dates_series.dt.is_leap_year\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  is_month_end\n",
      " |      Indicates whether the date is the last day of the month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or array\n",
      " |          For Series, returns a Series with boolean values.\n",
      " |          For DatetimeIndex, returns a boolean array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_month_start : Return a boolean indicating whether the date\n",
      " |          is the first day of the month.\n",
      " |      is_month_end : Return a boolean indicating whether the date\n",
      " |          is the last day of the month.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n",
      " |      >>> s\n",
      " |      0   2018-02-27\n",
      " |      1   2018-02-28\n",
      " |      2   2018-03-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> s.dt.is_month_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      >>> s.dt.is_month_end\n",
      " |      0    False\n",
      " |      1    True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2018-02-27\", periods=3)\n",
      " |      >>> idx.is_month_start\n",
      " |      array([False, False, True])\n",
      " |      >>> idx.is_month_end\n",
      " |      array([False, True, False])\n",
      " |  \n",
      " |  is_month_start\n",
      " |      Indicates whether the date is the first day of the month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or array\n",
      " |          For Series, returns a Series with boolean values.\n",
      " |          For DatetimeIndex, returns a boolean array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_month_start : Return a boolean indicating whether the date\n",
      " |          is the first day of the month.\n",
      " |      is_month_end : Return a boolean indicating whether the date\n",
      " |          is the last day of the month.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n",
      " |      >>> s\n",
      " |      0   2018-02-27\n",
      " |      1   2018-02-28\n",
      " |      2   2018-03-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      >>> s.dt.is_month_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      >>> s.dt.is_month_end\n",
      " |      0    False\n",
      " |      1    True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2018-02-27\", periods=3)\n",
      " |      >>> idx.is_month_start\n",
      " |      array([False, False, True])\n",
      " |      >>> idx.is_month_end\n",
      " |      array([False, True, False])\n",
      " |  \n",
      " |  is_quarter_end\n",
      " |      Indicator for whether the date is the last day of a quarter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_quarter_end : Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      quarter : Return the quarter of the date.\n",
      " |      is_quarter_start : Similar property indicating the quarter start.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n",
      " |      ...                    periods=4)})\n",
      " |      >>> df.assign(quarter=df.dates.dt.quarter,\n",
      " |      ...           is_quarter_end=df.dates.dt.is_quarter_end)\n",
      " |             dates  quarter    is_quarter_end\n",
      " |      0 2017-03-30        1             False\n",
      " |      1 2017-03-31        1              True\n",
      " |      2 2017-04-01        2             False\n",
      " |      3 2017-04-02        2             False\n",
      " |      \n",
      " |      >>> idx = pd.date_range('2017-03-30', periods=4)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_quarter_end\n",
      " |      array([False,  True, False, False])\n",
      " |  \n",
      " |  is_quarter_start\n",
      " |      Indicator for whether the date is the first day of a quarter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_quarter_start : Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      quarter : Return the quarter of the date.\n",
      " |      is_quarter_end : Similar property for indicating the quarter start.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n",
      " |      ...                   periods=4)})\n",
      " |      >>> df.assign(quarter=df.dates.dt.quarter,\n",
      " |      ...           is_quarter_start=df.dates.dt.is_quarter_start)\n",
      " |             dates  quarter  is_quarter_start\n",
      " |      0 2017-03-30        1             False\n",
      " |      1 2017-03-31        1             False\n",
      " |      2 2017-04-01        2              True\n",
      " |      3 2017-04-02        2             False\n",
      " |      \n",
      " |      >>> idx = pd.date_range('2017-03-30', periods=4)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-03-30', '2017-03-31', '2017-04-01', '2017-04-02'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_quarter_start\n",
      " |      array([False, False,  True, False])\n",
      " |  \n",
      " |  is_year_end\n",
      " |      Indicate whether the date is the last day of the year.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_year_start : Similar property indicating the start of the year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n",
      " |      >>> dates\n",
      " |      0   2017-12-30\n",
      " |      1   2017-12-31\n",
      " |      2   2018-01-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> dates.dt.is_year_end\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-12-30\", periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_year_end\n",
      " |      array([False,  True, False])\n",
      " |  \n",
      " |  is_year_start\n",
      " |      Indicate whether the date is the first day of a year.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DatetimeIndex\n",
      " |          The same type as the original data with boolean values. Series will\n",
      " |          have the same name and index. DatetimeIndex will have the same\n",
      " |          name.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_year_end : Similar property indicating the last day of the year.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This method is available on Series with datetime values under\n",
      " |      the ``.dt`` accessor, and directly on DatetimeIndex.\n",
      " |      \n",
      " |      >>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n",
      " |      >>> dates\n",
      " |      0   2017-12-30\n",
      " |      1   2017-12-31\n",
      " |      2   2018-01-01\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> dates.dt.is_year_start\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> idx = pd.date_range(\"2017-12-30\", periods=3)\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2017-12-30', '2017-12-31', '2018-01-01'],\n",
      " |                    dtype='datetime64[ns]', freq='D')\n",
      " |      \n",
      " |      >>> idx.is_year_start\n",
      " |      array([False, False,  True])\n",
      " |  \n",
      " |  microsecond\n",
      " |      The microseconds of the datetime.\n",
      " |  \n",
      " |  minute\n",
      " |      The minutes of the datetime.\n",
      " |  \n",
      " |  month\n",
      " |      The month as January=1, December=12.\n",
      " |  \n",
      " |  nanosecond\n",
      " |      The nanoseconds of the datetime.\n",
      " |  \n",
      " |  quarter\n",
      " |      The quarter of the date.\n",
      " |  \n",
      " |  second\n",
      " |      The seconds of the datetime.\n",
      " |  \n",
      " |  time\n",
      " |      Returns numpy array of datetime.time. The time part of the Timestamps.\n",
      " |  \n",
      " |  timetz\n",
      " |      Returns numpy array of datetime.time also containing timezone\n",
      " |      information. The time part of the Timestamps.\n",
      " |  \n",
      " |  tz\n",
      " |      Return timezone, if any.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime.tzinfo, pytz.tzinfo.BaseTZInfo, dateutil.tz.tz.tzfile, or None\n",
      " |          Returns None when the array is tz-naive.\n",
      " |  \n",
      " |  week\n",
      " |      The week ordinal of the year.\n",
      " |  \n",
      " |  weekday\n",
      " |      The day of the week with Monday=0, Sunday=6.\n",
      " |      \n",
      " |      Return the day of the week. It is assumed the week starts on\n",
      " |      Monday, which is denoted by 0 and ends on Sunday which is denoted\n",
      " |      by 6. This method is available on both Series with datetime\n",
      " |      values (using the `dt` accessor) or DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or Index\n",
      " |          Containing integers indicating the day number.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dt.dayofweek : Alias.\n",
      " |      Series.dt.weekday : Alias.\n",
      " |      Series.dt.day_name : Returns the name of the day of the week.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n",
      " |      >>> s.dt.dayofweek\n",
      " |      2016-12-31    5\n",
      " |      2017-01-01    6\n",
      " |      2017-01-02    0\n",
      " |      2017-01-03    1\n",
      " |      2017-01-04    2\n",
      " |      2017-01-05    3\n",
      " |      2017-01-06    4\n",
      " |      2017-01-07    5\n",
      " |      2017-01-08    6\n",
      " |      Freq: D, dtype: int64\n",
      " |  \n",
      " |  weekofyear\n",
      " |      The week ordinal of the year.\n",
      " |  \n",
      " |  year\n",
      " |      The year of the datetime.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Properties:\n",
      " |  \n",
      " |  __init__(self, data, orig)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.PandasDelegate:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return a string representation for a particular object.\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __annotations__ = {'_accessors': typing.Set[str], '_deprecations': typ...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.NoNewAttributesMixin:\n",
      " |  \n",
      " |  __setattr__(self, key, value)\n",
      " |      Implement setattr(self, name, value).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dt_Series.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int64Index', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt64Index', 'UInt8Dtype', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__getattr__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_config', '_hashtable', '_is_numpy_dev', '_lib', '_libs', '_np_version_under1p14', '_np_version_under1p15', '_np_version_under1p16', '_np_version_under1p17', '_np_version_under1p18', '_testing', '_tslib', '_typing', '_version', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
     ]
    }
   ],
   "source": [
    "print(dir(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_frame in module pandas.core.indexes.multi:\n",
      "\n",
      "from_frame(df, sortorder=None, names=None) method of builtins.type instance\n",
      "    Make a MultiIndex from a DataFrame.\n",
      "    \n",
      "    .. versionadded:: 0.24.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    df : DataFrame\n",
      "        DataFrame to be converted to MultiIndex.\n",
      "    sortorder : int, optional\n",
      "        Level of sortedness (must be lexicographically sorted by that\n",
      "        level).\n",
      "    names : list-like, optional\n",
      "        If no names are provided, use the column names, or tuple of column\n",
      "        names if the columns is a MultiIndex. If a sequence, overwrite\n",
      "        names with the given sequence.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    MultiIndex\n",
      "        The MultiIndex representation of the given DataFrame.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    MultiIndex.from_arrays : Convert list of arrays to MultiIndex.\n",
      "    MultiIndex.from_tuples : Convert list of tuples to MultiIndex.\n",
      "    MultiIndex.from_product : Make a MultiIndex from cartesian product\n",
      "                              of iterables.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([['HI', 'Temp'], ['HI', 'Precip'],\n",
      "    ...                    ['NJ', 'Temp'], ['NJ', 'Precip']],\n",
      "    ...                   columns=['a', 'b'])\n",
      "    >>> df\n",
      "          a       b\n",
      "    0    HI    Temp\n",
      "    1    HI  Precip\n",
      "    2    NJ    Temp\n",
      "    3    NJ  Precip\n",
      "    \n",
      "    >>> pd.MultiIndex.from_frame(df)\n",
      "    MultiIndex([('HI',   'Temp'),\n",
      "                ('HI', 'Precip'),\n",
      "                ('NJ',   'Temp'),\n",
      "                ('NJ', 'Precip')],\n",
      "               names=['a', 'b'])\n",
      "    \n",
      "    Using explicit names, instead of the column names\n",
      "    \n",
      "    >>> pd.MultiIndex.from_frame(df, names=['state', 'observation'])\n",
      "    MultiIndex([('HI',   'Temp'),\n",
      "                ('HI', 'Precip'),\n",
      "                ('NJ',   'Temp'),\n",
      "                ('NJ', 'Precip')],\n",
      "               names=['state', 'observation'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.MultiIndex.from_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  C\n",
      "0      Gaurav  1\n",
      "11   Abhiskek  2\n",
      "2     Krishna  3\n",
      "3   Abhishek2  4\n",
      "                N1  N2\n",
      "Name      Roll        \n",
      "Gaurav    1      1  44\n",
      "Abhiskek  2      2  65\n",
      "Krishna   3      3  78\n",
      "Abhishek2 4      4  98\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame([[\"Gaurav\",1], (\"Abhiskek\",2), (\"Krishna\",3), (\"Abhishek2\",4)],\n",
    "                    index=[0,11,2,3], \n",
    "                    columns=[\"Name\", \"C\"]\n",
    ")\n",
    "print(df3)\n",
    "idx = pd.MultiIndex.from_frame(df3,names=(\"Name\", \"Roll\"))\n",
    "r=pd.DataFrame({\"N1\":[1,2,3,4],\"N2\":[44,65,78,98]},index=idx)\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
